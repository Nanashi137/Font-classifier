{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import HENetdataset\n",
    "from dataset.transformation import augmenter, to_tensor\n",
    "from model.lightning_wraper import HENetWrapper\n",
    "from model.henet import HENet\n",
    "\n",
    "import os \n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    StochasticWeightAveraging\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"F:/processed/\"\n",
    "img_list = os.listdir(path) \n",
    "img_paths = []\n",
    "for img in img_list:\n",
    "    img_paths.append(path + img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split data\n",
    "\n",
    "random.shuffle(img_paths) \n",
    "\n",
    "total_size = len(img_paths)\n",
    "train_size = int(0.8*total_size)\n",
    "test_size  = int(0.1*total_size) \n",
    "valid_size =  total_size - train_size - test_size\n",
    "\n",
    "train_data = img_paths[:train_size]\n",
    "test_data  = img_paths[train_size:train_size + test_size]\n",
    "valid_data = img_paths[train_size + test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataset\n",
    "train_dataset =  HENetdataset(img_paths  = train_data, transform=augmenter)\n",
    "test_dataset  =  HENetdataset(img_paths  = test_data,  transform=to_tensor)\n",
    "valid_dataset =  HENetdataset(img_paths  = valid_data, transform=to_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader \n",
    "batch_size = 128\n",
    "pwf = False\n",
    "pwt = True\n",
    "train_loader =  DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers= 8,  persistent_workers= pwt)\n",
    "\n",
    "valid_loader =  DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers= 8,  persistent_workers= pwf)\n",
    "\n",
    "test_loader  =  DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, num_workers= 8,  persistent_workers= pwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "n_classes = 100\n",
    "lr = 0.01\n",
    "model = HENetWrapper(model=HENet(n_classes=n_classes),\n",
    "                     num_classes=n_classes,\n",
    "                     learning_rate=lr\n",
    "                     )\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: f:\\HENet\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                            | Type                | Params | Mode  | In sizes          | Out sizes        \n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "0  | model                           | HENet               | 11.2 M | train | [5, 3, 224, 224]  | [5, 100]         \n",
      "1  | model.backbone                  | Sequential          | 11.2 M | train | [5, 3, 224, 224]  | [5, 512, 7, 7]   \n",
      "2  | model.backbone.0                | Conv2d              | 9.4 K  | train | [5, 3, 224, 224]  | [5, 64, 112, 112]\n",
      "3  | model.backbone.1                | BatchNorm2d         | 128    | train | [5, 64, 112, 112] | [5, 64, 112, 112]\n",
      "4  | model.backbone.2                | ReLU                | 0      | train | [5, 64, 112, 112] | [5, 64, 112, 112]\n",
      "5  | model.backbone.3                | MaxPool2d           | 0      | train | [5, 64, 112, 112] | [5, 64, 56, 56]  \n",
      "6  | model.backbone.4                | Sequential          | 147 K  | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "7  | model.backbone.4.0              | BasicBlock          | 74.0 K | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "8  | model.backbone.4.0.conv1        | Conv2d              | 36.9 K | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "9  | model.backbone.4.0.bn1          | BatchNorm2d         | 128    | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "10 | model.backbone.4.0.relu         | ReLU                | 0      | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "11 | model.backbone.4.0.conv2        | Conv2d              | 36.9 K | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "12 | model.backbone.4.0.bn2          | BatchNorm2d         | 128    | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "13 | model.backbone.4.1              | BasicBlock          | 74.0 K | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "14 | model.backbone.4.1.conv1        | Conv2d              | 36.9 K | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "15 | model.backbone.4.1.bn1          | BatchNorm2d         | 128    | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "16 | model.backbone.4.1.relu         | ReLU                | 0      | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "17 | model.backbone.4.1.conv2        | Conv2d              | 36.9 K | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "18 | model.backbone.4.1.bn2          | BatchNorm2d         | 128    | train | [5, 64, 56, 56]   | [5, 64, 56, 56]  \n",
      "19 | model.backbone.5                | Sequential          | 525 K  | train | [5, 64, 56, 56]   | [5, 128, 28, 28] \n",
      "20 | model.backbone.5.0              | BasicBlock          | 230 K  | train | [5, 64, 56, 56]   | [5, 128, 28, 28] \n",
      "21 | model.backbone.5.0.conv1        | Conv2d              | 73.7 K | train | [5, 64, 56, 56]   | [5, 128, 28, 28] \n",
      "22 | model.backbone.5.0.bn1          | BatchNorm2d         | 256    | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "23 | model.backbone.5.0.relu         | ReLU                | 0      | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "24 | model.backbone.5.0.conv2        | Conv2d              | 147 K  | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "25 | model.backbone.5.0.bn2          | BatchNorm2d         | 256    | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "26 | model.backbone.5.0.downsample   | Sequential          | 8.4 K  | train | [5, 64, 56, 56]   | [5, 128, 28, 28] \n",
      "27 | model.backbone.5.0.downsample.0 | Conv2d              | 8.2 K  | train | [5, 64, 56, 56]   | [5, 128, 28, 28] \n",
      "28 | model.backbone.5.0.downsample.1 | BatchNorm2d         | 256    | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "29 | model.backbone.5.1              | BasicBlock          | 295 K  | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "30 | model.backbone.5.1.conv1        | Conv2d              | 147 K  | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "31 | model.backbone.5.1.bn1          | BatchNorm2d         | 256    | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "32 | model.backbone.5.1.relu         | ReLU                | 0      | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "33 | model.backbone.5.1.conv2        | Conv2d              | 147 K  | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "34 | model.backbone.5.1.bn2          | BatchNorm2d         | 256    | train | [5, 128, 28, 28]  | [5, 128, 28, 28] \n",
      "35 | model.backbone.6                | Sequential          | 2.1 M  | train | [5, 128, 28, 28]  | [5, 256, 14, 14] \n",
      "36 | model.backbone.6.0              | BasicBlock          | 919 K  | train | [5, 128, 28, 28]  | [5, 256, 14, 14] \n",
      "37 | model.backbone.6.0.conv1        | Conv2d              | 294 K  | train | [5, 128, 28, 28]  | [5, 256, 14, 14] \n",
      "38 | model.backbone.6.0.bn1          | BatchNorm2d         | 512    | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "39 | model.backbone.6.0.relu         | ReLU                | 0      | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "40 | model.backbone.6.0.conv2        | Conv2d              | 589 K  | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "41 | model.backbone.6.0.bn2          | BatchNorm2d         | 512    | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "42 | model.backbone.6.0.downsample   | Sequential          | 33.3 K | train | [5, 128, 28, 28]  | [5, 256, 14, 14] \n",
      "43 | model.backbone.6.0.downsample.0 | Conv2d              | 32.8 K | train | [5, 128, 28, 28]  | [5, 256, 14, 14] \n",
      "44 | model.backbone.6.0.downsample.1 | BatchNorm2d         | 512    | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "45 | model.backbone.6.1              | BasicBlock          | 1.2 M  | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "46 | model.backbone.6.1.conv1        | Conv2d              | 589 K  | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "47 | model.backbone.6.1.bn1          | BatchNorm2d         | 512    | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "48 | model.backbone.6.1.relu         | ReLU                | 0      | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "49 | model.backbone.6.1.conv2        | Conv2d              | 589 K  | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "50 | model.backbone.6.1.bn2          | BatchNorm2d         | 512    | train | [5, 256, 14, 14]  | [5, 256, 14, 14] \n",
      "51 | model.backbone.7                | Sequential          | 8.4 M  | train | [5, 256, 14, 14]  | [5, 512, 7, 7]   \n",
      "52 | model.backbone.7.0              | BasicBlock          | 3.7 M  | train | [5, 256, 14, 14]  | [5, 512, 7, 7]   \n",
      "53 | model.backbone.7.0.conv1        | Conv2d              | 1.2 M  | train | [5, 256, 14, 14]  | [5, 512, 7, 7]   \n",
      "54 | model.backbone.7.0.bn1          | BatchNorm2d         | 1.0 K  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "55 | model.backbone.7.0.relu         | ReLU                | 0      | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "56 | model.backbone.7.0.conv2        | Conv2d              | 2.4 M  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "57 | model.backbone.7.0.bn2          | BatchNorm2d         | 1.0 K  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "58 | model.backbone.7.0.downsample   | Sequential          | 132 K  | train | [5, 256, 14, 14]  | [5, 512, 7, 7]   \n",
      "59 | model.backbone.7.0.downsample.0 | Conv2d              | 131 K  | train | [5, 256, 14, 14]  | [5, 512, 7, 7]   \n",
      "60 | model.backbone.7.0.downsample.1 | BatchNorm2d         | 1.0 K  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "61 | model.backbone.7.1              | BasicBlock          | 4.7 M  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "62 | model.backbone.7.1.conv1        | Conv2d              | 2.4 M  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "63 | model.backbone.7.1.bn1          | BatchNorm2d         | 1.0 K  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "64 | model.backbone.7.1.relu         | ReLU                | 0      | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "65 | model.backbone.7.1.conv2        | Conv2d              | 2.4 M  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "66 | model.backbone.7.1.bn2          | BatchNorm2d         | 1.0 K  | train | [5, 512, 7, 7]    | [5, 512, 7, 7]   \n",
      "67 | model.reduce_channel            | Conv2d              | 51.3 K | train | [5, 512, 7, 7]    | [5, 100, 7, 7]   \n",
      "68 | model.heblock                   | HEBlock             | 0      | train | ?                 | ?                \n",
      "69 | model.pool                      | AdaptiveAvgPool2d   | 0      | train | [5, 100, 7, 7]    | [5, 100, 1, 1]   \n",
      "70 | model.fc                        | Linear              | 10.1 K | train | [5, 100]          | [5, 100]         \n",
      "71 | f1                              | MulticlassF1Score   | 0      | train | ?                 | ?                \n",
      "72 | accuracy                        | MulticlassAccuracy  | 0      | train | ?                 | ?                \n",
      "73 | precision                       | MulticlassPrecision | 0      | train | ?                 | ?                \n",
      "74 | recall                          | MulticlassRecall    | 0      | train | ?                 | ?                \n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.952    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\FWC\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 1/750 [00:02<36:56,  0.34it/s, v_num=0, train_acc=0.931, train_loss=0.187, train_f1=0.927, train_pre=0.938, train_rec=0.931, val_loss=0.143, val_accuracy=0.934, val_f1=0.928]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\FWC\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "# Define trainer \n",
    "\n",
    "training_callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", mode=\"min\"),\n",
    "        StochasticWeightAveraging(swa_lrs=1e-2),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=\"./output\",\n",
    "            save_top_k=2,\n",
    "            monitor=\"val_loss\",\n",
    "            filename=\"HENet-{epoch:02d}-{val_loss:.4f}-{val_accuracy:.4f}\",\n",
    "            save_last=True,\n",
    "        ),\n",
    "        ModelSummary(-1)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer = L.Trainer(max_epochs=40, callbacks=training_callbacks)\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=valid_loader,\n",
    "    ckpt_path= None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 94/94 [00:27<00:00,  3.42it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9301738142967224\n",
      "         test_f1            0.9247004389762878\n",
      "        test_loss           0.1509121060371399\n",
      "     test_precision         0.9305580854415894\n",
      "       test_recall          0.9301738142967224\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.1509121060371399,\n",
       "  'test_acc': 0.9301738142967224,\n",
       "  'test_f1': 0.9247004389762878,\n",
       "  'test_precision': 0.9305580854415894,\n",
       "  'test_recall': 0.9301738142967224}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_loader) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
